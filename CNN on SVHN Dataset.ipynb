{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    return loadmat(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "training_data = load_data(\"Dataset/SVHN/train_32x32.mat\")\n",
    "test_data = load_data(\"Dataset/SVHN/test_32x32.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = training_data[\"X\"]\n",
    "x_test = test_data[\"X\"]\n",
    "\n",
    "y_train = training_data[\"y\"]\n",
    "y_test = test_data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset\n",
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, features, labels, transform = None):\n",
    "        self.features = torch.tensor(features).permute([3, 2, 0, 1])\n",
    "        self.labels = torch.LongTensor(labels).squeeze_()\n",
    "        self.labels[self.labels == 10] = 0\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        sample = self.features[index], self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transform(object):\n",
    "    def __init__(self, divide_by = 255.0):\n",
    "        self.divide_by = divide_by\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x / self.divide_by\n",
    "        sample = x, y\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader and test_loader\n",
    "\n",
    "transform = transform()\n",
    "\n",
    "train_data = Dataset(x_train, y_train, transform = transform)\n",
    "train_loader = DataLoader(train_data, batch_size = 512, shuffle = True)\n",
    "\n",
    "test_data = Dataset(x_test, y_test, transform = transform)\n",
    "test_loader = DataLoader(test_data, batch_size = 512, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for i, j in train_loader:\n",
    "    print(i.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # 1st Convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 3, stride = 1, padding = 2)\n",
    "        nn.init.normal_(self.conv1.weight, std = 0.001)\n",
    "        nn.init.constant_(self.conv1.bias, 0)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "    \n",
    "        # 2nd Convolution\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 3, stride = 1, padding = 1)\n",
    "        nn.init.normal_(self.conv2.weight, std = 0.001)\n",
    "        nn.init.constant_(self.conv2.bias, 0)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        \n",
    "        # 3rd Convolution\n",
    "        self.conv3 = nn.Conv2d(in_channels = 12, out_channels = 36, kernel_size = 3, stride = 1, padding = 1)\n",
    "        nn.init.normal_(self.conv3.weight, std = 0.001)\n",
    "        nn.init.constant_(self.conv3.bias, 0)\n",
    "        self.bn3 = nn.BatchNorm2d(36)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        \n",
    "        # fully connected layer\n",
    "        self.fc1 = nn.Linear(36 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "        \n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # conv layers\n",
    "        x = self.maxpool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.maxpool2(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.maxpool3(self.relu3(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        \n",
    "        # reshape the image\n",
    "        x = x.view(-1, 36 * 4 * 4)\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = self.dropout(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim = 1)\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 3, 32, 32]) torch.Size([512])\n",
      "torch.Size([512, 10])\n"
     ]
    }
   ],
   "source": [
    "# trying the model\n",
    "\"\"\"model = CNN()\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(images.shape, labels.shape)\n",
    "\n",
    "logits = model(images)\n",
    "print(logits.shape)\n",
    "loss = criterion(logits, labels)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def get_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # model out was log_softmax, doing torch_exp will convert them to softmax\n",
    "            ps = torch.exp(outputs)\n",
    "            \n",
    "            # get the class with highest probability\n",
    "            _, predicted = ps.topk(1, dim = 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.view(*predicted.shape)).sum().item()\n",
    " \n",
    "    model.train()\n",
    "    return 100 * correct / total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.5377659201622009, Test Accuracy: 73.22526121696373\n",
      "Epoch: 2, Training Loss: 0.32063308358192444, Test Accuracy: 81.2922556853104\n",
      "Epoch: 3, Training Loss: 0.2149576097726822, Test Accuracy: 84.17332513829133\n",
      "Epoch: 4, Training Loss: 0.7719606757164001, Test Accuracy: 85.33343577135832\n",
      "Epoch: 5, Training Loss: 0.687445878982544, Test Accuracy: 85.14904732636755\n",
      "Epoch: 6, Training Loss: 0.6759110689163208, Test Accuracy: 85.90580823601721\n",
      "Epoch: 7, Training Loss: 0.1418183445930481, Test Accuracy: 87.20036877688999\n",
      "Epoch: 8, Training Loss: 0.6663283109664917, Test Accuracy: 88.14535955746773\n",
      "Epoch: 9, Training Loss: 0.1753505915403366, Test Accuracy: 86.26306084818685\n",
      "Epoch: 10, Training Loss: 0.38802486658096313, Test Accuracy: 84.3999692685925\n",
      "Epoch: 11, Training Loss: 0.37755638360977173, Test Accuracy: 87.73048555623848\n",
      "Epoch: 12, Training Loss: 0.34831422567367554, Test Accuracy: 84.5958819913952\n",
      "Epoch: 13, Training Loss: 0.3810703158378601, Test Accuracy: 85.86739397664412\n",
      "Epoch: 14, Training Loss: 0.20947840809822083, Test Accuracy: 89.10187461585741\n",
      "Epoch: 15, Training Loss: 0.38076525926589966, Test Accuracy: 87.06207744314689\n",
      "Epoch: 16, Training Loss: 0.47930797934532166, Test Accuracy: 87.2541487400123\n",
      "Epoch: 17, Training Loss: 0.6279436349868774, Test Accuracy: 87.88414259373079\n",
      "Epoch: 18, Training Loss: 0.4868665635585785, Test Accuracy: 86.04409956976029\n",
      "Epoch: 19, Training Loss: 0.15628212690353394, Test Accuracy: 89.25553165334972\n",
      "Epoch: 20, Training Loss: 0.6683034896850586, Test Accuracy: 87.67670559311617\n",
      "Epoch: 21, Training Loss: 0.31264999508857727, Test Accuracy: 88.75230485556239\n",
      "Epoch: 22, Training Loss: 0.304046630859375, Test Accuracy: 88.62937922556853\n",
      "Epoch: 23, Training Loss: 0.1650783270597458, Test Accuracy: 88.96742470805162\n",
      "Epoch: 24, Training Loss: 0.6366451382637024, Test Accuracy: 87.00445605408727\n",
      "Epoch: 25, Training Loss: 0.4250447452068329, Test Accuracy: 88.52181929932391\n",
      "Epoch: 26, Training Loss: 0.45736661553382874, Test Accuracy: 86.99293177627536\n",
      "Epoch: 27, Training Loss: 0.22919943928718567, Test Accuracy: 87.7458512599877\n",
      "Epoch: 28, Training Loss: 0.1431453377008438, Test Accuracy: 87.68822987092808\n",
      "Epoch: 29, Training Loss: 0.4725625216960907, Test Accuracy: 88.54102642901044\n",
      "Epoch: 30, Training Loss: 0.15520256757736206, Test Accuracy: 88.64090350338046\n",
      "Epoch: 31, Training Loss: 0.08138289302587509, Test Accuracy: 88.8560233558697\n",
      "Epoch: 32, Training Loss: 0.41008344292640686, Test Accuracy: 87.96097111247695\n",
      "Epoch: 33, Training Loss: 0.4654947519302368, Test Accuracy: 87.00829748002458\n",
      "Epoch: 34, Training Loss: 0.21599160134792328, Test Accuracy: 89.10571604179471\n",
      "Epoch: 35, Training Loss: 0.3374391496181488, Test Accuracy: 88.25676090964966\n",
      "Epoch: 36, Training Loss: 0.16706331074237823, Test Accuracy: 89.1979102642901\n",
      "Epoch: 37, Training Loss: 0.4925149083137512, Test Accuracy: 84.17332513829133\n",
      "Epoch: 38, Training Loss: 0.18954889476299286, Test Accuracy: 86.46281499692687\n",
      "Epoch: 39, Training Loss: 0.29308807849884033, Test Accuracy: 88.16456668715428\n",
      "Epoch: 40, Training Loss: 0.24775604903697968, Test Accuracy: 87.86877688998156\n",
      "Epoch: 41, Training Loss: 0.3447904884815216, Test Accuracy: 87.8918254456054\n",
      "Epoch: 42, Training Loss: 0.15138785541057587, Test Accuracy: 88.16840811309157\n",
      "Epoch: 43, Training Loss: 0.14706791937351227, Test Accuracy: 87.78426551936079\n",
      "Epoch: 44, Training Loss: 0.20929361879825592, Test Accuracy: 88.4257836508912\n",
      "Epoch: 45, Training Loss: 0.16504719853401184, Test Accuracy: 89.52443146896128\n",
      "Epoch: 46, Training Loss: 0.25585711002349854, Test Accuracy: 89.7741241548863\n",
      "Epoch: 47, Training Loss: 0.05871601775288582, Test Accuracy: 88.52566072526122\n",
      "Epoch: 48, Training Loss: 0.20964306592941284, Test Accuracy: 88.00322679778733\n",
      "Epoch: 49, Training Loss: 0.20162510871887207, Test Accuracy: 87.49615857406269\n",
      "Epoch: 50, Training Loss: 0.3328956663608551, Test Accuracy: 87.25799016594961\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "model.train()\n",
    "\n",
    "# loss function as the model output is log_softmax\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "# optimizer\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "# number of epochs\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):   \n",
    "    for inputs,labels in (train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # clear the accumulated grads\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, labels)\n",
    "        \n",
    "        # compute gradients\n",
    "        loss.backward() \n",
    "        \n",
    "        # optimize\n",
    "        optimizer.step() \n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        accucacy = get_accuracy(model,test_loader)\n",
    "        print(f\"Epoch: {epoch + 1}, Training Loss: {loss.item()}, Test Accuracy: {accucacy}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
